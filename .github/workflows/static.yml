name: Deploy static content to Pages

on:
  push:
    branches: ["main"]
  schedule:
    - cron: "30 15 * * *"
    - cron: "30 17 * * *"
    - cron: "30 19 * * *"
    - cron: "30 21 * * *"
    - cron: "30 23 * * *"
    - cron: "30 1 * * *"
    - cron: "30 3 * * *"
    - cron: "30 5 * * *"
  workflow_dispatch:

permissions:
  contents: read
  pages: write
  id-token: write

concurrency:
  group: "pages"
  cancel-in-progress: true

jobs:
    build:
      runs-on: ubuntu-latest
      steps:
        - name: Checkout
          uses: actions/checkout@v4

        - name: Install dependencies
          run: |
            sudo apt update
            wget https://dl.google.com/linux/direct/google-chrome-stable_current_amd64.deb
            sudo apt install -y ./google-chrome-stable_current_amd64.deb
            pip install selenium bs4 lxml

        - name: Scrape site
          run: |
            mkdir -p website
            python3 scrape.py
            echo "=== Website dir after scrape ==="
            ls -R website || true
            # sanity check
            if [ ! -f website/index.html ]; then
              echo "ERROR: website/index.html not found"
              exit 1
            fi
        - name: Setup Pages
          uses: actions/configure-pages@v4
        - name: Upload artifact
          id: deployment
          uses: actions/upload-pages-artifact@v4
          with:
            path: website

    deploy:
      environment:
        name: github-pages
        url: ${{ steps.deployment.outputs.page_url }}
      runs-on: ubuntu-latest
      steps:
        - name: Deploy to GitHub Pages
          id: deployment
          uses: actions/deploy-pages@v4
